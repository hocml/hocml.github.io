---
title:  "Máy học dẫn những nhà toán học tới một bài toán không thể giải"
categories: jekyll update
permalink: myupdate.html
tags: [news, machinelearning, AI, mathematics]
---

*Bài toán "Trí tuệ nhân tạo" đơn giản đã đặt những nhà nghiên cứu chống lại "nghịch lý logic" được đưa ra bời nhà toán học nổi tiếng Kurt Gödel.*

Một nhóm nghiêm cứu đã gặp phải một câu hỏi không thể trả lời về mặt toán học, bởi vì nó liên quan tới "nghịch lý logic" được đưa ra bởi nhà toán học người Áo Kurt Gödel vào năm 1930s, bài toán này không thể giải được bằng toán học thuần túy.

Những nhà toán học đang làm việc trong lĩnh vực học máy, đưa ra một câu hỏi về "khả năng học" - liệu rằng một thuật toán có thể rút trích những quy luật từ một tập dữ liệu giới hạn? - liên quan tới một nghịch lý được gọi là "giả thuyết liên tục". Gödel đã chỉ ra rằng câu hỏi này không thể chứng minh có/không bằng cách sử  dụng toán học thuần túy. Kết quả mới nhất được đăng vào ngày 7/1 trên tạp chí [Nature Machine Intelligence](https://www.nature.com/articles/d41586-019-00083-3#ref-CR1).

"Đối với chúng tôi, nó là một điều bất ngờ" , Amir Yehudayoff tại Viện Công nghệ Technion, Israel ở Haifa nói, ông là đồng tác giả của bài báo. Ông nói rằng mặc dù có một số câu hỏi toán học cũng được biết tới là "không thể giải được", nhưng ông không hy vọng hiện tượng này xuất hiện trong một vấn đề tương đối đơn giản như là học máy.

John Tucker, một nhà khoa học máy tính tại Đại học Swansea ở Anh, nói rằng "kết quả của bài báo này đã cho thấy giới hạn về kiến ​​thức của chúng ta", về nền tảng cho cả toán học và học máy.

## Không phải tất cả những tập hợp là đều bằng nhau

Các nhà nghiên cứu thường định nghĩa "khả năng học" liên quan tới việc liệu một thuật toán có thể khái quát hóa kiến ​​thức của nó hay không. Thuật toán được cho trước những câu trả lời 'có hoặc không' cho những câu hỏi (dữ liệu gán nhãn) - chẳng hạn như câu hỏi "Hình ảnh này có hiển thị một con mèo không?" - với một tập giới hạn những mẫu dữ liệu, và sau đó phải đưa ra những dự đoán cho những dữ liệu mới.

Yehudayoff và các cộng sự của ông đã đi đến kết quả của họ trong khi điều tra mối liên hệ giữa khả năng học hỏi và "nén thông tin", liên quan tới việc tìm cách tóm tắt các đặc trưng nổi bật của một tập dữ liệu lớn trong một tập dữ liệu nhỏ hơn. Các tác giả đã phát hiện ra rằng khả năng nén thông tin một cách hiệu quả bản chất là một vấn đề trong "lý thuyết tập hợp" - tập hợp toán học của các đối tượng, chẳng hạn như các tập hợp trong sơ đồ Venn. Cụ thể, nó liên quan đến các kích thước khác nhau của các tập hợp chứa vô số đối tượng.

Georg Cantor, người sáng lập lý thuyết tập hợp, đã chứng minh vào những năm 1870 rằng không phải tất cả các tập hợp vô hạn đều được tạo ra bằng nhau: ví dụ, tập hợp các số nguyên nhỏ hơn so với tập hợp của tất cả các số thực. (Các số thực bao gồm các số vô tỷ, số hữu tỉ và số nguyên.) Cantor cũng cho rằng không thể có các tập hợp có kích thước trung gian - nghĩa là lớn hơn tập hợp các số nguyên nhưng nhỏ hơn tập hợp các số thực . Nhưng ông không thể chứng minh giả thuyết liên tục này, và cũng không có nhà toán học và nhà luận lý học đã theo ông làm được điều này.

Những nỗ lực của họ là vô ích. Một kết quả năm 1940 của Gôdel (được hoàn thành vào những năm 1960 bởi nhà toán học Hoa Kỳ Paul Cohen) cho thấy "giả thuyết liên tục" không thể được chứng minh là đúng hay sai bắt đầu từ các tiên đề chuẩn - những phát biểu được đưa ra là đúng - về lý thuyết tập hợp, thường được lấy làm nền tảng toán học cho những phát triển về toán học sau này.

Công trình của Gôdel và Cohen về giả thuyết liên tục ngụ ý rằng có thể tồn tại các vũ trụ toán học song song đều thích với toán học tiêu chuẩn - một trong những vũ trụ đó thêm "giả thuyết liên tục" vào các tiên đề chuẩn và do đó được tuyên bố là đúng và trong một vũ trụ khác nó được tuyên bố là sai.

## Khả năng học hỏi
Trong bài báo mới nhất, Yehudayoff và các cộng sự của mình định nghĩa khả năng học hỏi là khả năng đưa ra dự đoán về một tập dữ liệu lớn bằng cách lấy mẫu một số lượng nhỏ các điểm dữ liệu. Liên hệ đến vấn đề của Cantor, là có vô số cách chọn tập nhỏ hơn từ tập dữ liệu lớn, số cách chọn đó là một số vô cực chưa biết.

Các tác giả của họ tiếp tục chỉ ra rằng nếu "giả thuyết liên tục" là đúng, một mẫu nhỏ là đủ để thực hiện phép ngoại suy. Nhưng nếu nó là sai, không có tập mẫu hữu hạn nào có thể là đủ. Bằng cách này, họ chỉ ra rằng khả năng học hỏi tương đương với giả thuyết liên tục. Do đó, bài toán về khả năng học hỏi cũng ở trạng thái lấp lửng chỉ có thể được giải bằng cách chọn vũ trụ tiên đề.

Kết quả của bài báo cũng giúp cung cấp một sự hiểu biết rộng hơn về khả năng học hỏi, Yehudayoff nói. "Mối liên hệt giữa giữa khả năng "nén thông tin" và "khái quát hóa" này thực sự cơ bản nếu bạn muốn hiểu về  "học".

Các nhà nghiên cứu đã phát hiện ra một số vấn đề tương tự, cũng không thể giải được, Peter O’Hearn, một nhà khoa học máy tính tại Đại học College London, nói. Cụ thể, sau công việc của Gôdel, Alan Turing - người đồng sáng lập lý thuyết thuật toán - đã tìm thấy một loại những câu hỏi mà không chương trình máy tính nào có thể đưa ra được đáp án với bất kì hữu hạn bước.

Nhưng sự không chắc chắn trong các kết quả mới nhất "thường hiếm thấy", và đáng ngạc nhiên hơn, O’Hearn cho biết thêm: nó chỉ ra những gì mà Gôdel thấy là không hoàn hảo trong bất kỳ ngôn ngữ toán học nào. Những phát hiện này có thể sẽ rất quan trọng đối với lý thuyết về học máy, ông nói thêm, mặc dù ông không chắc chắn rằng nó sẽ có nhiều tác động đến thực tiễn.

__________________________________________________________________________________________________________________________
nguồn : [nature](https://www.nature.com/articles/d41586-019-00083-3)


